{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 08\n",
    "\n",
    "This is a set of problems which focus on goodness-of-fit tests for various models of data. \n",
    "\n",
    "<b>This homework is due Tuesday 6/26 at midnight. Hand it in with Lab 08 by the due date and time. </b>\n",
    " \n",
    "\n",
    "<b>Be sure to select Run All from the Cell menu before submitting this notebook as your solution!</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook specific \n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from IPython.display import display_html\n",
    "from IPython.display import display\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML \n",
    "\n",
    "# General useful imports\n",
    "import numpy as np\n",
    "from numpy import log,arange,linspace,mean, var, std,exp\n",
    "from scipy.special import comb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.mlab as mlab\n",
    "from numpy.random import seed,random, randint, uniform, choice, binomial, geometric, poisson, exponential, normal \n",
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Numpy basic stats functions\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.statistics.html\n",
    "\n",
    "X = [1,2,3]\n",
    "\n",
    "# mean of a list\n",
    "mean(X)\n",
    "\n",
    "# population variance\n",
    "var(X)\n",
    "\n",
    "# sample variance\n",
    "var(X,ddof=1)\n",
    "\n",
    "# population standard deviation\n",
    "std(X)\n",
    "\n",
    "# sample standard deviation\n",
    "std(X,ddof=1)\n",
    "\n",
    "# Scipy statistical functions\n",
    "\n",
    "from scipy.stats import norm,expon,chi2 \n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "\n",
    "# The following will work with norm replaced by expon or by chi2\n",
    "\n",
    "# given random variable X (e.g., housing prices) normally distributed with  mu = 60, sigma = 40\n",
    "\n",
    "\n",
    "# pdf of the distribution\n",
    "norm.pdf(x=50,loc=60,scale=40)\n",
    "chi2.pdf(x=10,df=5)\n",
    "\n",
    "#a. Find P(X<50)\n",
    "norm.cdf(x=50,loc=60,scale=40) # 0.4012936743170763\n",
    "chi2.cdf(x=10,df=5)\n",
    "\n",
    "#a. Find P(X>50)\n",
    "norm.sf(x=50,loc=60,scale=40) # 0.4012936743170763\n",
    "chi2.sf(x=10,df=5)\n",
    "\n",
    "#c. Find P(60<X<80)\n",
    "norm.cdf(x=80,loc=60,scale=40) - norm.cdf(x=60,loc=60,scale=40)\n",
    "\n",
    "#d. how much top most 5% expensive house cost at least? or find x where P(X>x) = 0.05\n",
    "norm.isf(q=0.05,loc=60,scale=40)\n",
    "\n",
    "#e. how much top most 5% cheapest house cost at least? or find x where P(X<x) = 0.05\n",
    "norm.ppf(q=0.05,loc=60,scale=40)\n",
    "\n",
    "#f give the endpoints of the range for the central alpha percent of the distribution\n",
    "norm.interval(alpha=0.3, loc=60, scale=140)\n",
    "\n",
    "# Same for exponential distribution\n",
    "beta = 5    # mean of distribution\n",
    "\n",
    "\n",
    "\n",
    "# Utility functions\n",
    "\n",
    "# Round to 4 decimal places\n",
    "def round4(x):\n",
    "    return round(float(x)+0.00000000001,4)\n",
    "\n",
    "def round4List(X):\n",
    "    return [round(float(x)+0.00000000001,4) for x in X]\n",
    "\n",
    "def show_histogram(freqs,bins,title=\"Data Histogram\"):\n",
    "    plt.bar(bins[:-1],freqs,width=(bins[1]-bins[0]),align='edge',tick_label=round4List(bins[:-1]),edgecolor='k')\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Bins [Lo .. Hi)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Zero (Optional)\n",
    "\n",
    "I suggest that you consolidate the code from lab so that you can take a set of observations\n",
    "and a theoretical distribution (given as a list of probabilies) and print out the\n",
    "results of the test. Use this in problems 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs = set of observations; Probs = matching set of probabilities for the distribution to test fittness for\n",
    "# los = level of significance\n",
    "\n",
    "def do_chi2_hypothesis_test(Obs,Probs,los, H0 = \"The data follows the given distribution.\"):\n",
    "    expected_p = B(len(Obs),p)\n",
    "    expected = [expected_p[x]*300 for x in range(len(expected_p) - 1)]\n",
    "    chi2_presum = [(((Obs[i] - expected[i])**2)/expected[i]) for i in range(len(Obs))]\n",
    "    chi2_val = 0\n",
    "    for x in range(len(chi2_presum)):\n",
    "        chi2_val += chi2_presum[x]\n",
    "    critval = chi2.ppf(q=(1 - los), df=4)\n",
    "    if (critval >= chi2_val):\n",
    "        print(\"Fail to reject: \" + str(round4(chi2_val)))\n",
    "    else:\n",
    "        print(\"Reject: \" + str(round4(chi2_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test your function on Example B.1 on p.285 of Schaum's (same as we went over in class) and confirm that you implemented it correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c5ee3cafdc72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mUniform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdo_chi2_hypothesis_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mUniform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-b1157acd45e9>\u001b[0m in \u001b[0;36mdo_chi2_hypothesis_test\u001b[0;34m(Obs, Probs, los, H0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_chi2_hypothesis_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mProbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The data follows the given distribution.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mexpected_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexpected_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_p\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mchi2_presum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "Obs = [80,65,70,85]\n",
    "n = len(Obs)\n",
    "Uniform = [1/n for k in range(n)]\n",
    "do_chi2_hypothesis_test(Obs,Uniform,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem One (Chi^2 Hypothesis Testing -- Normal Distribution)\n",
    "\n",
    "For this problem, we would like you to apply the $\\chi^2$ test to data following the normal distribution. The basic ideas of the test are shown in Schaum's Appendix B, Example B.5 on p.288. Before starting this problem, please look at that example. \n",
    "\n",
    "The $\\chi^2$ test is designed for discrete distributions, so to test a continuous distribution we need to\n",
    "convert it into a discrete one by \"binning\" the data into some number of intervals. The first part of this problem shows how to do this easily using the numpy <code>histogram</code> function.  \n",
    " \n",
    "## Part A\n",
    "\n",
    "In order to bin the observed and theoretical values, we will use the numpy function <code>histogram</code>, which takes a list of outcomes and counts the frequencies in <code>num_bins</code> bins spread evenly over the range; it returns a list of frequencies for each bin (= how many values from the data set ended up in that bin) and a list of the bin boundaries. \n",
    "\n",
    "For example, we can separate a set of observed data points into 4 bins as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1a = [ 11.69690176,   6.94784341,   4.21136807,   9.21746662,   6.84108737,\n",
    "  13.08583604 , 12.22008482 ,  7.37578756 ,  7.19696017,  11.58233656,\n",
    "   8.79227342 ,  9.77640417 , 13.29730199 ,  9.92861583 ,  6.82766429,\n",
    "  10.55806493 , 12.74073126 ,  8.13821793 , 13.4815449,    9.67843858,\n",
    "  12.49634904 , 12.834129  ,   9.66832643 ,  6.30537823,   9.78097709,\n",
    "  15.10102417 ,  7.77790787 ,  8.17102049 , 10.51004163,  10.89602475]\n",
    "\n",
    "obs,bins = np.histogram(X1a,bins=5)\n",
    "\n",
    "print(obs)\n",
    "print(bins)\n",
    "    \n",
    "show_histogram(obs,bins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bins are the ranges (values rounded to 4 decimal places): \n",
    "\n",
    "<pre>\n",
    "[4.2114 .. 6.3893), [6.3893 .. 8.5672), [8.5672 .. 10.7452),  [ 10.7452 .. 12.9231),  [12.9231 .. 15.101]. \n",
    "</pre>\n",
    "Note that the variable <code>bins</code> is the list of boundaries between each of the bins, so its length is <code>num_bins + 1</code>. \n",
    "\n",
    "Now complete the following function stub to take a data set (which is potentially from a normal distribution with mean mu and standard deviation sigma) and bin the data into a set Obs of observed frequencies, and also produce a list Probs of expected probabilities for these bins if the data followed a normal distribution with the same mean and standard deviation as the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs_and_normal_probs(X,num_bins):\n",
    "    pass\n",
    "\n",
    "    return (obs,probs,bins)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function on the data in X1a\n",
    "\n",
    "\"\"\"   Uncomment to test\n",
    "Obs,Probs,bins = get_obs_and_normal_probs(X1a,5)\n",
    "\n",
    "show_histogram(Obs,bins,\"Observed Frequencies\")\n",
    "# convert probabilities into expected frequencies\n",
    "Exp = [p*len(X1a) for p in Probs]\n",
    "show_histogram(Exp,bins,\"Expected Frequencies\")\n",
    "\"\"\"\n",
    "\n",
    "# Also: try 10 bins or 20 and see what happens!\n",
    "\n",
    "# As a rough rule-of-thumb, you want at least approximately 5 values in each bin, so \n",
    "# the largest number of bins would be # of data points / 5. In this case, that would give\n",
    "# us an upper bound of 30/5 = 6 bins.  That is why we chose 5. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "Now complete the following stub to do the normal distribution test on the data in X1a, as in the lab, using the code from Problem 0 (if you wish).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_chi2_normal_test(X,num_bins,los):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1b = X1a\n",
    "do_chi2_normal_test(X1b,5,0.1)\n",
    "\n",
    "# You should get a large p-value, which means that the data is very, very likely to be normal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C\n",
    "\n",
    "Now test the following data set using 5 bins and los = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1c = [2,5,4,3,6,5,4,2,3,2,3,2,3,2,3,2,7,3,2,6,6,6,6,6,7,4,5,6,8,7,1,2,8,8,8,8,8,8,8,5,4,3,6,5,4,5,8,]\n",
    "do_chi2_normal_test(X1c,5,0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Two (Chi^2 Normal Test for Real Data)\n",
    "\n",
    "In this problem you will test a number of real data sets to see how well a normal distribution\n",
    "fits the data. \n",
    "\n",
    "## Part A\n",
    "\n",
    "First we will test a small fraction of the BU GPA data to determine if the GPAs follow a normal distribution to a 0.05 level of significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the file \"BUDataSmall.csv\" to see if the GPA data fits a normal distribution with los = 0.05\n",
    "# Use 10 bins. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the file \"BUData.csv\" to see if the whole data set of GPAs fits a normal distribution with los = 0.05\n",
    "# Use 50 bins.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the file \"BUData.csv\" to see if the whole data set of APCredits fits a normal distribution with los = 0.05\n",
    "# Use 50 bins.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the file \"StudentData3.csv\" to see if the SAT_TOTAL data fits a normal distribution with los = 0.05\n",
    "# Use 20 bins.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing using Normal Probability Plots\n",
    "\n",
    "Basic reference:  http://www.itl.nist.gov/div898/handbook/eda/section3/normprpl.htm\n",
    "\n",
    "From the link http://www.itl.nist.gov/div898/handbook/eda/section3/eda3676.htm:\n",
    "\n",
    "\"The test statistic is the correlation coefficient $\\rho$ of the points that \n",
    "make up a normal probability plot. This test statistic is compared with the \n",
    "critical value below. If the test statistic is less than the tabulated value, \n",
    "the null hypothesis that the data came from a population with a normal \n",
    "distribution is rejected.\"\n",
    "\n",
    "NOTE: This framework uses an inverse table (compared with the textbook definition of LOS), since\n",
    "you reject when your statistic $\\rho$ is less than the value in the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical Values for the normal probability plot correlation coefficient test for\n",
    "# normality of a data set, from http://www.itl.nist.gov/div898/handbook/eda/section3/eda3676.htm\n",
    "\n",
    "# First column is N = number of samples, second is for 0.01 LOS, third is for 0.05 LOS\n",
    "\n",
    "CV = [[   3   ,      0.8687        ,  0.8790],\n",
    "[   4   ,      0.8234        ,  0.8666],\n",
    "[   5   ,      0.8240        ,  0.8786],\n",
    "[   6   ,      0.8351        ,  0.8880],\n",
    "[   7   ,      0.8474        ,  0.8970],\n",
    "[   8   ,      0.8590        ,  0.9043],\n",
    "[   9   ,      0.8689        ,  0.9115],\n",
    "[  10   ,      0.8765        ,  0.9173],\n",
    "[  11   ,      0.8838        ,  0.9223],\n",
    "[  12   ,      0.8918        ,  0.9267],\n",
    "[  13   ,      0.8974        ,  0.9310],\n",
    "[  14   ,      0.9029        ,  0.9343],\n",
    "[  15   ,      0.9080        ,  0.9376],\n",
    "[  16   ,      0.9121        ,  0.9405],\n",
    "[  17   ,      0.9160        ,  0.9433],\n",
    "[  18   ,      0.9196        ,  0.9452],\n",
    "[  19   ,      0.9230        ,  0.9479],\n",
    "[  20   ,      0.9256        ,  0.9498],\n",
    "[  21   ,      0.9285        ,  0.9515],\n",
    "[  22   ,      0.9308        ,  0.9535],\n",
    "[  23   ,      0.9334        ,  0.9548],\n",
    "[  24   ,      0.9356        ,  0.9564],\n",
    "[  25   ,      0.9370        ,  0.9575],\n",
    "[  26   ,      0.9393        ,  0.9590],\n",
    "[  27   ,      0.9413        ,  0.9600],\n",
    "[  28   ,      0.9428        ,  0.9615],\n",
    "[  29   ,      0.9441        ,  0.9622],\n",
    "[  30   ,      0.9462        ,  0.9634],\n",
    "[  31   ,      0.9476        ,  0.9644],\n",
    "[  32   ,      0.9490        ,  0.9652],\n",
    "[  33   ,      0.9505        ,  0.9661],\n",
    "[  34   ,      0.9521        ,  0.9671],\n",
    "[  35   ,      0.9530        ,  0.9678],\n",
    "[  36   ,      0.9540        ,  0.9686],\n",
    "[  37   ,      0.9551        ,  0.9693],\n",
    "[  38   ,      0.9555        ,  0.9700],\n",
    "[  39   ,      0.9568        ,  0.9704],\n",
    "[  40   ,      0.9576        ,  0.9712],\n",
    "[  41   ,      0.9589        ,  0.9719],\n",
    "[  42   ,      0.9593        ,  0.9723],\n",
    "[  43   ,      0.9609        ,  0.9730],\n",
    "[  44   ,      0.9611        ,  0.9734],\n",
    "[  45   ,      0.9620        ,  0.9739],\n",
    "[  46   ,      0.9629        ,  0.9744],\n",
    "[  47   ,      0.9637        ,  0.9748],\n",
    "[  48   ,      0.9640        ,  0.9753],\n",
    "[  49   ,      0.9643        ,  0.9758],\n",
    "[  50   ,      0.9654        ,  0.9761],\n",
    "[  55   ,      0.9683        ,  0.9781],\n",
    "[  60   ,      0.9706        ,  0.9797],\n",
    "[  65   ,      0.9723        ,  0.9809],\n",
    "[  70   ,      0.9742        ,  0.9822],\n",
    "[  75   ,      0.9758        ,  0.9831],\n",
    "[  80   ,      0.9771        ,  0.9841],\n",
    "[  85   ,      0.9784        ,  0.9850],\n",
    "[  90   ,      0.9797        ,  0.9857],\n",
    "[  95   ,      0.9804        ,  0.9864],\n",
    "[ 100   ,      0.9814        ,  0.9869],\n",
    "[ 110   ,      0.9830        ,  0.9881],\n",
    "[ 120   ,      0.9841        ,  0.9889],\n",
    "[ 130   ,      0.9854        ,  0.9897],\n",
    "[ 140   ,      0.9865        ,  0.9904],\n",
    "[ 150   ,      0.9871        ,  0.9909],\n",
    "[ 160   ,      0.9879        ,  0.9915],\n",
    "[ 170   ,      0.9887        ,  0.9919],\n",
    "[ 180   ,      0.9891        ,  0.9923],\n",
    "[ 190   ,      0.9897        ,  0.9927],\n",
    "[ 200   ,      0.9903        ,  0.9930],\n",
    "[ 210   ,      0.9907        ,  0.9933],\n",
    "[ 220   ,      0.9910        ,  0.9936],\n",
    "[ 230   ,      0.9914        ,  0.9939],\n",
    "[ 240   ,      0.9917        ,  0.9941],\n",
    "[ 250   ,      0.9921        ,  0.9943],\n",
    "[ 260   ,      0.9924        ,  0.9945],\n",
    "[ 270   ,      0.9926        ,  0.9947],\n",
    "[ 280   ,      0.9929        ,  0.9949],\n",
    "[ 290   ,      0.9931        ,  0.9951],\n",
    "[ 300   ,      0.9933        ,  0.9952],\n",
    "[ 310   ,      0.9936        ,  0.9954],\n",
    "[ 320   ,      0.9937        ,  0.9955],\n",
    "[ 330   ,      0.9939        ,  0.9956],\n",
    "[ 340   ,      0.9941        ,  0.9957],\n",
    "[ 350   ,      0.9942        ,  0.9958],\n",
    "[ 360   ,      0.9944        ,  0.9959],\n",
    "[ 370   ,      0.9945        ,  0.9960],\n",
    "[ 380   ,      0.9947        ,  0.9961],\n",
    "[ 390   ,      0.9948        ,  0.9962],\n",
    "[ 400   ,      0.9949        ,  0.9963],\n",
    "[ 410   ,      0.9950        ,  0.9964],\n",
    "[ 420   ,      0.9951        ,  0.9965],\n",
    "[ 430   ,      0.9953        ,  0.9966],\n",
    "[ 440   ,      0.9954        ,  0.9966],\n",
    "[ 450   ,      0.9954        ,  0.9967],\n",
    "[ 460   ,      0.9955        ,  0.9968],\n",
    "[ 470   ,      0.9956        ,  0.9968],\n",
    "[ 480   ,      0.9957        ,  0.9969],\n",
    "[ 490   ,      0.9958        ,  0.9969],\n",
    "[ 500   ,      0.9959        ,  0.9970],\n",
    "[ 525   ,      0.9961        ,  0.9972],\n",
    "[ 550   ,      0.9963        ,  0.9973],\n",
    "[ 575   ,      0.9964        ,  0.9974],\n",
    "[ 600   ,      0.9965        ,  0.9975],\n",
    "[ 625   ,      0.9967        ,  0.9976],\n",
    "[ 650   ,      0.9968        ,  0.9977],\n",
    "[ 675   ,      0.9969        ,  0.9977],\n",
    "[ 700   ,      0.9970        ,  0.9978],\n",
    "[ 725   ,      0.9971        ,  0.9979],\n",
    "[ 750   ,      0.9972        ,  0.9980],\n",
    "[ 775   ,      0.9973        ,  0.9980],\n",
    "[ 800   ,      0.9974        ,  0.9981],\n",
    "[ 825   ,      0.9975        ,  0.9981],\n",
    "[ 850   ,      0.9975        ,  0.9982],\n",
    "[ 875   ,      0.9976        ,  0.9982],\n",
    "[ 900   ,      0.9977        ,  0.9983],\n",
    "[ 925   ,      0.9977        ,  0.9983],\n",
    "[ 950   ,      0.9978        ,  0.9984],\n",
    "[ 975   ,      0.9978        ,  0.9984],\n",
    "[1000   ,      0.9979        ,  0.9984]]\n",
    "\n",
    "\n",
    "# Approximation to uniform order statistic medians due to Fillben:\n",
    "#  http://www1.cmc.edu/pages/faculty/MONeill/Math152/Handouts/filliben.pdf\n",
    "\n",
    "def U(i,n):\n",
    "    if(i == n):\n",
    "        return 0.5**(1/n)\n",
    "    elif(i == 1):\n",
    "        return 1 - 0.5**(1/n)\n",
    "    else:\n",
    "        return (i - 0.3175)/(n + 0.365)\n",
    "\n",
    "# Normal Order Statistic Medians\n",
    "\n",
    "def NOSM(i,n,mu,sigma):\n",
    "    return norm.ppf(q=U(i,n),loc=mu,scale=sigma)\n",
    "\n",
    "def getCVIndex(n,lo,hi):\n",
    "    if(lo >= hi):\n",
    "        return lo\n",
    "    mid = (lo + hi)//2\n",
    "    if(CV[mid][0] == n):\n",
    "        return mid\n",
    "    elif(CV[mid][0] < n):\n",
    "        return getCVIndex(n,mid+1,hi)\n",
    "    else:\n",
    "        return getCVIndex(n,lo,mid-1)\n",
    "    \n",
    "# returns the critical value or the next lower value if not in the table\n",
    "\n",
    "def getCriticalValue(N,los):\n",
    "    N = min(N,1000)\n",
    "    i = getCVIndex(N,0,len(CV))\n",
    "    if(los == 0.01):\n",
    "        return CV[i][1]\n",
    "    else:\n",
    "        return CV[i][2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Three (Tests using Normal Probability Plots)\n",
    "\n",
    "In this problem you will write a function similar to the one above, but this time\n",
    "performing a test for fittness of the normal distribution using a normal probability\n",
    "plot. A big difference from the $\\chi^2$ test is that we can do this directly on\n",
    "the data and no \"binning\" of values is necessary. Thus, it is usually a more sensitive\n",
    "test than $\\chi^2$ for normal data. \n",
    "\n",
    "The cell above contains all the code you need to do this test, supposing that your\n",
    "test data is in the list Y, here the outline of what you need to do in filling in\n",
    "the stub in the next cell:\n",
    "\n",
    "    N = len(Y)\n",
    "\n",
    "    los = level of significance of test.\n",
    "\n",
    "The predicted values on the x-axis are produced as follows:\n",
    "\n",
    "    X = [NOSM(i,N,mean(X),std(X,ddof=1)) for i in range(1,N+1)]          # we use the sample std dev\n",
    "\n",
    "and the test is performed as follows:\n",
    "\n",
    "    If rho(X,Y) < getCriticalValue(N,los) then reject, else fail to reject. \n",
    "\n",
    "To display the probability plot, sort Y and draw a scatter plot of X against the sorted Y. To draw the linear prediction, plot X against X. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "Complete the following function stub and test it on the data X1a with los = 0.01. \n",
    "\n",
    "You must draw the probability plot and then print out the result of the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pplot_normal_test(Y,los):\n",
    "    pass\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test X1a with los = 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B \n",
    "\n",
    "Now we would like you to test the data in X1c. It will fail, even at a 0.1 level of significance, because it is fundamentally a discrete distribution (the outcomes are all integers), and the probability plot expects a continuous distribution. Hence, in this case the $\\chi^2$ test is more appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test X1c with los = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts C -- F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test X2a with los = 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test X2b with los = 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test X2c with los = 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test X2d with los = 0.05\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
